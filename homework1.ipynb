{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2: Handwritten Digits Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 1: Feedforward Neural Network (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任务定义：利用前馈神经网络识别手写数字  \n",
    "输入：手写数字图片  \n",
    "输出：识别结果  \n",
    "性能评价：准确率  \n",
    "环境：python3.5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入所需要的包\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义三层全连接神经网络，每一层都是线性的\n",
    "class simpleNet(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        #传入的参数分别为：输入的维度、第一层网络的神经元个数、第二层网络的神经元个数、第三层网络（输出层）的神经元个数\n",
    "        super(simpleNet, self).__init__()\n",
    "        self.layer1 = nn.Linear(in_dim, n_hidden_1)\n",
    "        self.layer2 = nn.Linear(n_hidden_1, n_hidden_2)\n",
    "        self.layer3 = nn.Linear(n_hidden_2, out_dim)\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "# 添加激活函数，改进网络的非线性\n",
    "class Activation_Net(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(Activation_Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1), nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2), nn.ReLU(True))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x\n",
    "    \n",
    "# 添加一个快速收敛的方法——批标准化\n",
    "class Batch_Net(nn.Module):\n",
    "    def __init__(self, in_dim, n_hidden_1, n_hidden_2, out_dim):\n",
    "        super(Batch_Net, self).__init__()\n",
    "        self.layer1 = nn.Sequential(nn.Linear(in_dim, n_hidden_1),nn.BatchNorm1d(n_hidden_1), nn.ReLU(True))\n",
    "        self.layer2 = nn.Sequential(nn.Linear(n_hidden_1, n_hidden_2),nn.BatchNorm1d(n_hidden_2), nn.ReLU(True))\n",
    "        self.layer3 = nn.Sequential(nn.Linear(n_hidden_2, out_dim))\n",
    " \n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "batch_size = 64\n",
    "learning_rate = 1e-2\n",
    "num_epoches = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********\n",
      "epoch1000\n",
      "loss is 0.4930\n",
      "**********\n",
      "epoch2000\n",
      "loss is 0.1622\n",
      "**********\n",
      "epoch3000\n",
      "loss is 0.2389\n",
      "**********\n",
      "epoch4000\n",
      "loss is 0.2321\n",
      "**********\n",
      "epoch5000\n",
      "loss is 0.1347\n",
      "**********\n",
      "epoch6000\n",
      "loss is 0.3404\n",
      "**********\n",
      "epoch7000\n",
      "loss is 0.4059\n",
      "**********\n",
      "epoch8000\n",
      "loss is 0.1814\n",
      "**********\n",
      "epoch9000\n",
      "loss is 0.2015\n",
      "**********\n",
      "epoch10000\n",
      "loss is 0.3582\n",
      "**********\n",
      "epoch11000\n",
      "loss is 0.1209\n",
      "**********\n",
      "epoch12000\n",
      "loss is 0.3579\n",
      "**********\n",
      "epoch13000\n",
      "loss is 0.3057\n",
      "**********\n",
      "epoch14000\n",
      "loss is 0.2809\n",
      "**********\n",
      "epoch15000\n",
      "loss is 0.3333\n",
      "**********\n",
      "epoch16000\n",
      "loss is 0.2478\n",
      "**********\n",
      "epoch17000\n",
      "loss is 0.1817\n",
      "**********\n",
      "epoch18000\n",
      "loss is 0.2659\n",
      "**********\n",
      "epoch19000\n",
      "loss is 0.2286\n",
      "**********\n",
      "epoch20000\n",
      "loss is 0.2716\n",
      "**********\n",
      "epoch21000\n",
      "loss is 0.1252\n",
      "**********\n",
      "epoch22000\n",
      "loss is 0.2456\n",
      "**********\n",
      "epoch23000\n",
      "loss is 0.2494\n",
      "**********\n",
      "epoch24000\n",
      "loss is 0.3555\n",
      "**********\n",
      "epoch25000\n",
      "loss is 0.3145\n",
      "**********\n",
      "epoch26000\n",
      "loss is 0.0995\n",
      "**********\n",
      "epoch27000\n",
      "loss is 0.2365\n",
      "**********\n",
      "epoch28000\n",
      "loss is 0.2197\n",
      "**********\n",
      "epoch29000\n",
      "loss is 0.0950\n",
      "**********\n",
      "epoch30000\n",
      "loss is 0.1210\n",
      "**********\n",
      "epoch31000\n",
      "loss is 0.5134\n",
      "**********\n",
      "epoch32000\n",
      "loss is 0.2760\n",
      "**********\n",
      "epoch33000\n",
      "loss is 0.4412\n",
      "**********\n",
      "epoch34000\n",
      "loss is 0.2140\n",
      "**********\n",
      "epoch35000\n",
      "loss is 0.4999\n",
      "**********\n",
      "epoch36000\n",
      "loss is 0.1703\n",
      "**********\n",
      "epoch37000\n",
      "loss is 0.2244\n",
      "**********\n",
      "epoch38000\n",
      "loss is 0.3911\n",
      "**********\n",
      "epoch39000\n",
      "loss is 0.2323\n",
      "**********\n",
      "epoch40000\n",
      "loss is 0.2651\n",
      "**********\n",
      "epoch41000\n",
      "loss is 0.3470\n",
      "**********\n",
      "epoch42000\n",
      "loss is 0.2849\n",
      "**********\n",
      "epoch43000\n",
      "loss is 0.2222\n",
      "**********\n",
      "epoch44000\n",
      "loss is 0.1052\n",
      "**********\n",
      "epoch45000\n",
      "loss is 0.2225\n",
      "**********\n",
      "epoch46000\n",
      "loss is 0.3372\n",
      "**********\n",
      "epoch47000\n",
      "loss is 0.0912\n",
      "**********\n",
      "epoch48000\n",
      "loss is 0.3427\n",
      "**********\n",
      "epoch49000\n",
      "loss is 0.1443\n",
      "**********\n",
      "epoch50000\n",
      "loss is 0.1387\n",
      "Test Loss:0.272025, Acc:0.923800\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    # 数据预处理\n",
    "    data_tf = transforms.Compose([transforms.ToTensor(), transforms.Normalize([0.5], [0.5])])\n",
    "    # 下载训练集-MNIST手写数字训练集\n",
    "    train_dataset = datasets.MNIST(root=\"./MNIST_data/\", train=True, transform=data_tf, download=True)\n",
    "    test_dataset = datasets.MNIST(root=\"./MNIST_data/\", train=False, transform=data_tf)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    # 选择并导入网络模型\n",
    "    # (输入维度28x28，两个隐层分别是300和100，最后输出结果是10，因为一共有10个分类)\n",
    "    model = simpleNet(28*28, 300, 100, 10)\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "    # 定义损失函数和优化函数\n",
    "    criterion = nn.CrossEntropyLoss()#损失函数：损失函数交叉熵\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)# 优化函数1：随机梯度下降法\n",
    "    optimizer_ = optim.Adam(model.parameters(), lr=learning_rate)# 优化函数2：Adam算法\n",
    "    # 训练网络\n",
    "    for epoch in range(50000):\n",
    "        img, label = iter(train_loader).next()\n",
    "        if torch.cuda.is_available():\n",
    "            img = Variable(img.view(img.size(0), -1)).cuda()\n",
    "            label = Variable(label).cuda()\n",
    "        else:\n",
    "            img = Variable(img.view(img.size(0), -1))\n",
    "            label = Variable(label)\n",
    "        # 前向传播\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()# 梯度归零\n",
    "        loss.backward()\n",
    "        optimizer.step()# 更新参数\n",
    "        if(epoch + 1) % 1000 == 0:\n",
    "            print('*'*10)\n",
    "            print('epoch{}'.format(epoch+1))\n",
    "            print('loss is {:.4f}'.format(loss.item()))\n",
    "    # 测试网络\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_acc = 0\n",
    "    for data in test_loader:\n",
    "        img, label = data\n",
    "        img = img.view(img.size(0), -1)\n",
    "        if torch.cuda.is_available():\n",
    "            img = Variable(img).cuda()\n",
    "            label = Variable(label).cuda()\n",
    "        else:\n",
    "            img = Variable(img)\n",
    "            label = Variable(label)\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        eval_loss += loss.item() * label.size(0)\n",
    "        _, pred = torch.max(out, 1)\n",
    "        num_correct = (pred == label).sum()\n",
    "        eval_acc += num_correct.item()\n",
    "    print('Test Loss:{:.6f}, Acc:{:.6f}'.format(eval_loss / (len(test_dataset)), eval_acc / (len(test_dataset))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2: Convolutional Neural Network (30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任务定义：利用卷积神经网络识别手写数字  \n",
    "输入：手写数字图片  \n",
    "输出：识别结果  \n",
    "性能评价：准确率  \n",
    "环境：python3.5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入所需要的包\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义网络结构\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AlexNet,self).__init__()\n",
    "\n",
    "        # 由于MNIST为28x28， 而最初AlexNet的输入图片是227x227的。所以网络层数和参数需要调节\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1) #AlexCONV1(3,96, k=11,s=4,p=0)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)#AlexPool1(k=3, s=2)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # self.conv2 = nn.Conv2d(96, 256, kernel_size=5,stride=1,padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)#AlexCONV2(96, 256,k=5,s=1,p=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2,stride=2)#AlexPool2(k=3,s=2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)#AlexCONV3(256,384,k=3,s=1,p=1)\n",
    "        # self.conv4 = nn.Conv2d(384, 384, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)#AlexCONV4(384, 384, k=3,s=1,p=1)\n",
    "        self.conv5 = nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1)#AlexCONV5(384, 256, k=3, s=1,p=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)#AlexPool3(k=3,s=2)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.fc6 = nn.Linear(256*3*3, 1024)  #AlexFC6(256*6*6, 4096)\n",
    "        self.fc7 = nn.Linear(1024, 512) #AlexFC6(4096,4096)\n",
    "        self.fc8 = nn.Linear(512, 10)  #AlexFC6(4096,1000)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = x.view(-1, 256 * 3 * 3)#Alex: x = x.view(-1, 256*6*6)\n",
    "        x = self.fc6(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc7(x)\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc8(x)\n",
    "        x = self.dropout(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 图片变换\n",
    "transform = transforms.Compose([\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.RandomGrayscale(),\n",
    "                    transforms.ToTensor(),\n",
    "])\n",
    "transform1 = transforms.Compose([\n",
    "                    transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "trainset = torchvision.datasets.MNIST(root='./MNIST_data',train=True,download=True,transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,shuffle=True,num_workers=0)# windows下num_workers设置为0，不然有bug\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./MNIST_data',train=False,download=True,transform=transform1)\n",
    "testloader = torch.utils.data.DataLoader(testset,batch_size=100,shuffle=False,num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu1): ReLU()\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu2): ReLU()\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu3): ReLU()\n",
       "  (fc6): Linear(in_features=2304, out_features=1024, bias=True)\n",
       "  (fc7): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (fc8): Linear(in_features=512, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.5)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net\n",
    "net = AlexNet()\n",
    "\n",
    "# 损失函数:这里用交叉熵\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器 这里用SGD\n",
    "optimizer = optim.SGD(net.parameters(),lr=1e-3, momentum=0.9)\n",
    "\n",
    "# device : GPU or CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Start Training!\n",
      "[1, 60000] loss:2.2983\n",
      "[2, 60000] loss:2.3027\n",
      "[3, 60000] loss:2.2937\n",
      "[4, 60000] loss:2.2547\n",
      "[5, 60000] loss:0.6345\n",
      "[6, 60000] loss:0.3230\n",
      "[7, 60000] loss:0.3502\n",
      "[8, 60000] loss:0.2666\n",
      "[9, 60000] loss:0.1415\n",
      "[10, 60000] loss:0.1994\n",
      "[11, 60000] loss:0.2125\n",
      "[12, 60000] loss:0.2834\n",
      "[13, 60000] loss:0.1174\n",
      "[14, 60000] loss:0.0457\n",
      "[15, 60000] loss:0.0400\n",
      "[16, 60000] loss:0.0501\n",
      "[17, 60000] loss:0.0707\n",
      "[18, 60000] loss:0.0499\n",
      "[19, 60000] loss:0.0258\n",
      "[20, 60000] loss:0.0714\n",
      "Finished Traning\n",
      "Accuracy of the network on the 10000 test images:97.03%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "print(\"Start Training!\")\n",
    "\n",
    "#训练次数\n",
    "num_epochs = 20 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0\n",
    "    batch_size = 100\n",
    "\n",
    "    for i, data in enumerate(trainloader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print('[%d, %5d] loss:%.4f'%(epoch+1, (i+1)*100, loss.item()))\n",
    "print(\"Finished Traning\")\n",
    "#保存训练模型\n",
    "torch.save(net, 'MNIST.pkl')\n",
    "net = torch.load('MNIST.pkl')\n",
    "#开始识别\n",
    "with torch.no_grad():\n",
    "    #在接下来的代码中，所有Tensor的requires_grad都会被设置为False\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        out = net(images)\n",
    "        _, predicted = torch.max(out.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images:{}%'.format(100 * correct / total)) #输出识别准确率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boston Housing Problem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 2. Bayes classifier (20 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任务定义：利用高斯贝叶斯模型来根据特征对波士顿房价分类  \n",
    "输入：波士顿房子的特征    \n",
    "输出：波士顿房子房价的类别    \n",
    "性能评价：准确率  \n",
    "环境：python3.5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入所需要的包\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATI</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATI  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296    15.3   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242    17.8   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242    17.8   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222    18.7   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222    18.7   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...     ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273    21.0   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273    21.0   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273    21.0   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273    21.0   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273    21.0   \n",
       "\n",
       "          B  LSTAT  MEDV  \n",
       "0    396.90   4.98  24.0  \n",
       "1    396.90   9.14  21.6  \n",
       "2    392.83   4.03  34.7  \n",
       "3    394.63   2.94  33.4  \n",
       "4    396.90   5.33  36.2  \n",
       "..      ...    ...   ...  \n",
       "501  391.99   9.67  22.4  \n",
       "502  396.90   9.08  20.6  \n",
       "503  396.90   5.64  23.9  \n",
       "504  393.45   6.48  22.0  \n",
       "505  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 导入数据\n",
    "data = pd.read_csv('./Boston.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATI</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  PTRATI  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296    15.3   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242    17.8   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242    17.8   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222    18.7   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222    18.7   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...     ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273    21.0   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273    21.0   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273    21.0   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273    21.0   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273    21.0   \n",
       "\n",
       "          B  LSTAT  \n",
       "0    396.90   4.98  \n",
       "1    396.90   9.14  \n",
       "2    392.83   4.03  \n",
       "3    394.63   2.94  \n",
       "4    396.90   5.33  \n",
       "..      ...    ...  \n",
       "501  391.99   9.67  \n",
       "502  396.90   9.08  \n",
       "503  396.90   5.64  \n",
       "504  393.45   6.48  \n",
       "505  396.90   7.88  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取X和y\n",
    "X = data.ix[:,:-1]\n",
    "y = data['MEDV'] \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    506.000000\n",
       "mean      22.532806\n",
       "std        9.197104\n",
       "min        5.000000\n",
       "25%       17.025000\n",
       "50%       21.200000\n",
       "75%       25.000000\n",
       "max       50.000000\n",
       "Name: MEDV, dtype: float64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分为四个等级，断点为17、21和25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2.0\n",
       "1      2.0\n",
       "2      3.0\n",
       "3      3.0\n",
       "4      3.0\n",
       "      ... \n",
       "501    2.0\n",
       "502    1.0\n",
       "503    2.0\n",
       "504    2.0\n",
       "505    0.0\n",
       "Name: MEDV, Length: 506, dtype: float64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(y)):\n",
    "    if y[i]<=17:\n",
    "        y[i] = 0\n",
    "    elif y[i]<=21:\n",
    "        y[i] = 1\n",
    "    elif y[i]<=25:\n",
    "        y[i] = 2\n",
    "    else:\n",
    "        y[i] = 3\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13)\n",
      "(506,)\n"
     ]
    }
   ],
   "source": [
    "# 转换为numpy数组\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 贝叶斯学习函数\n",
    "def Bys_learn(X,y):\n",
    "    model = GaussianNB()\n",
    "    model.fit(X,y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# demo\n",
    "bys = Bys_learn(X,y)\n",
    "bys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 贝叶斯预测函数\n",
    "def Bys_predict(model,X):\n",
    "    y = model.predict(X)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3., 2., 3., 3., 3., 3., 2., 2., 1., 2., 2., 2., 2., 2., 2., 2., 2.,\n",
       "       1., 1., 1.])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 预测的结果\n",
    "y = Bys_predict(bys,X)\n",
    "y[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 划分数据集\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练\n",
    "bys = Bys_learn(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 0. 3. 1. 0. 2. 3. 0. 2. 0. 2. 1. 1. 0. 0. 0. 2. 2. 2.]\n",
      "Accuracy:0.9411764705882353\n"
     ]
    }
   ],
   "source": [
    "# 测试\n",
    "y_pred_test = Bys_predict(bys,X_test)\n",
    "print(y_pred_test[:20])\n",
    "print('Accuracy:',end = '')\n",
    "print(accuracy_score(y_pred_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method 4: Neural Network for classification or regression (20 points) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "任务定义：利用神经网络来根据特征对波士顿房价回归  \n",
    "输入：波士顿房子的特征    \n",
    "输出：波士顿房子房价    \n",
    "性能评价：均方差损失  \n",
    "环境：python3.5  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入所需要的包\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入数据，并预处理\n",
    "X = np.array(data.ix[:,:-1])\n",
    "y = np.array(data['MEDV'])\n",
    "X = preprocessing.scale(X)\n",
    "y = preprocessing.scale(y.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义超参数\n",
    "data_size, D_input, D_output, D_hidden = X.shape[0], X.shape[1], 1, 50\n",
    "lr = 1e-5\n",
    "epoch = 20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sigmoid函数\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 权重w1和w2\n",
    "w1 = np.random.randn(D_input, D_hidden)\n",
    "w2 = np.random.randn(D_hidden, D_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 484.0730\n",
      "epoch: 1000 loss: 0.2754\n",
      "epoch: 2000 loss: 0.2749\n",
      "epoch: 3000 loss: 0.2747\n",
      "epoch: 4000 loss: 0.2745\n",
      "epoch: 5000 loss: 0.2743\n",
      "epoch: 6000 loss: 0.2742\n",
      "epoch: 7000 loss: 0.2742\n",
      "epoch: 8000 loss: 0.2741\n",
      "epoch: 9000 loss: 0.2742\n",
      "epoch: 10000 loss: 0.2742\n",
      "epoch: 11000 loss: 0.2742\n",
      "epoch: 12000 loss: 0.2743\n",
      "epoch: 13000 loss: 0.2744\n",
      "epoch: 14000 loss: 0.2745\n",
      "epoch: 15000 loss: 0.2746\n",
      "epoch: 16000 loss: 0.2747\n",
      "epoch: 17000 loss: 0.2748\n",
      "epoch: 18000 loss: 0.2749\n",
      "epoch: 19000 loss: 0.2750\n"
     ]
    }
   ],
   "source": [
    "# 训练\n",
    "for i in range(epoch):\n",
    "    # 前向传播\n",
    "    h = np.dot(X, w1)\n",
    "    h_ = sigmoid(h)\n",
    "    y_ = np.dot(h, w2)\n",
    "    # 打印误差\n",
    "    mse = np.sum((y - y_) ** 2)/len(y_)\n",
    "    if i % 1000 == 0:\n",
    "        print('epoch: {} loss: {:.4f}'.format(i, mse))\n",
    "    # 误差反向传播\n",
    "    g_y_ = 2 * (y_ - y)\n",
    "    g_w2 = np.dot(h_.T, g_y_)\n",
    "    g_h_ = np.dot(g_y_, w2.T)\n",
    "    g_h = g_h_ * sigmoid(h) * (1 - sigmoid(h))\n",
    "    g_w1 = np.dot(X.T, g_h)\n",
    "    # 参数更新\n",
    "    w1 -= lr * g_w1\n",
    "    w2 -= lr * g_w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
